{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yes/no recognition.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ArmgzafqBk4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Trainig the model used for Yes/No recognition (real-time  prediction)"
      ]
    },
    {
      "metadata": {
        "id": "_KlPuavGBm43",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# feature extractoring and preprocessing data\n",
        "import librosa\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import keras\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from scipy.fftpack import fft\n",
        " \n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mt66oVUcBnfW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    # short time fourier transform\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    # Mel frequency cepstral coefficients\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "                                              sr=sample_rate).T, axis=0)\n",
        "    return  mfccs, chroma, mel, contrast, tonnetz\n",
        " \n",
        " \n",
        "def parse_audio_files(parent_dir, sub_dirs, file_ext=\"*.wav\"):\n",
        "    features, labels = np.empty((0, 193)), np.empty(0)\n",
        "    for label, sub_dir in enumerate(sub_dirs):\n",
        "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
        "            mfccs, chroma, mel, contrast, tonnetz = extract_feature(fn)\n",
        "            ext_features = np.hstack([mfccs, chroma, mel, contrast, tonnetz])\n",
        "            features = np.vstack([features, ext_features])\n",
        "            str = (fn.split('\\\\')[2])[0]\n",
        "            if str == 'n':\n",
        "                labels = np.append(labels, 0)\n",
        "            else:\n",
        "                labels = np.append(labels, 1)\n",
        " \n",
        "    return np.array(features), np.array(labels, dtype=np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S9gwQlHXBrIh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parent_dir = 'db'\n",
        "tr_sub_dirs = [\"train\"]\n",
        "ts_sub_dirs = [\"test\"]\n",
        " \n",
        "tr_features, tr_labels = parse_audio_files(parent_dir, tr_sub_dirs)\n",
        "ts_features, ts_labels = parse_audio_files(parent_dir, ts_sub_dirs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJLQakrhBwGs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        " \n",
        "# creating layers\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(tr_features.shape[1],)))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VhJ2uSCLB38b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "# fitting data into the model\n",
        "model.fit(tr_features,\n",
        "          tr_labels,\n",
        "          epochs=1,\n",
        "          batch_size=1)\n",
        "results = model.evaluate(ts_features, ts_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ppZGCNzqB4HU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5LxDGEJVCAUB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "\n",
        "\n",
        "> here we used the save model to predict the user input (voice) in a while loop\n"
      ]
    },
    {
      "metadata": {
        "id": "_KOMPC5ECS9l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CII8Q8SnCieC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def audio_input():\n",
        "    folder = 'db/test1/'\n",
        "    for the_file in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, the_file)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        " \n",
        "    # audio specifications\n",
        "    FORMAT = pyaudio.paInt16\n",
        "    CHANNELS = 2\n",
        "    RATE = 44100\n",
        "    CHUNK = 1024\n",
        "    RECORD_SECONDS = 2  # for recording 1 sec audio :\\\n",
        "    WAVE_OUTPUT_FILENAME = \"test.wav\"\n",
        " \n",
        "    audio = pyaudio.PyAudio()\n",
        " \n",
        "    # start Recording\n",
        "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
        "                        rate=RATE, input=True,\n",
        "                        frames_per_buffer=CHUNK)\n",
        "    print(\"recording...\")\n",
        "    frames = []\n",
        " \n",
        "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "        data = stream.read(CHUNK)\n",
        "        frames.append(data)\n",
        "    print(\"finished recording\")\n",
        " \n",
        "    # stop Recording\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    audio.terminate()\n",
        " \n",
        "    # writing the wav file into the test db/test1\n",
        "    waveFile = wave.open('db/test1/' + WAVE_OUTPUT_FILENAME, 'wb')\n",
        "    waveFile.setnchannels(CHANNELS)\n",
        "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
        "    waveFile.setframerate(RATE)\n",
        "    waveFile.writeframes(b''.join(frames))\n",
        "    waveFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AEpl6Y01CoLP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "                                              sr=sample_rate).T, axis=0)\n",
        "    return mfccs, chroma, mel, contrast, tonnetz\n",
        " \n",
        " \n",
        "def parse_audio_files_pred(parent_dir, sub_dirs, file_ext=\"*.wav\"):\n",
        "    features = np.empty((0, 193))\n",
        "    for label, sub_dir in enumerate(sub_dirs):\n",
        "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
        "            mfccs, chroma, mel, contrast, tonnetz = extract_feature(fn)\n",
        "            ext_features = np.hstack([mfccs, chroma, mel, contrast, tonnetz])\n",
        "            features = np.vstack([features, ext_features])\n",
        "    return np.array(features)\n",
        "  \n",
        "parent_dir = 'db'\n",
        "pred_sub_dirs = [\"test1\"]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xZfWEsQdCv1u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Z0Igra0C0GY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    audio_input()\n",
        "    pred_features = parse_audio_files_pred(parent_dir, pred_sub_dirs)\n",
        "    predictions = loaded_model.predict(pred_features)\n",
        "    result = np.argmax(predictions)\n",
        "    if result == '1':\n",
        "        print('Yes')\n",
        "    else:\n",
        "        print('No')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70xr2AcxC4VZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plotting the features used in this model as input "
      ]
    },
    {
      "metadata": {
        "id": "C7bMKieQC-JF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aaE3JSeiDBT-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this addresses must be set according to your local device\n",
        "fn_no = r'C:\\Users\\pcstorm\\PycharmProjects\\Anaconda\\signal-project-keras\\signal2\\db\\test\\no0.wav'\n",
        "fn_yes = r'C:\\Users\\pcstorm\\PycharmProjects\\Anaconda\\signal-project-keras\\signal2\\db\\test\\yes20.wav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vv6pnju5DBfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    # short time fourier transform\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    # Mel frequency cepstral coefficients\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "                                              sr=sample_rate).T, axis=0)\n",
        "    return  mfccs, chroma, mel, contrast, tonnetz\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SqWTM_WIDZBP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mfccs, chroma, mel, contrast, tonnetz = extract_feature(fn_no)\n",
        "mfccs2, chroma2, mel2, contrast2, tonnetz2 = extract_feature(fn_yes)\n",
        " \n",
        "plot = plt.subplot(5, 2, 1)\n",
        "plot.set_title(\"mfcc-no\")\n",
        "plot.plot(mfccs)\n",
        " \n",
        "plot = plt.subplot(5, 2, 2)\n",
        "plot.set_title(\"mfcc-yes\")\n",
        "plot.plot(mfccs2)\n",
        " \n",
        "plot = plt.subplot(5, 2, 3)\n",
        "plot.set_title(\"chroma-no\")\n",
        "plot.plot(chroma)\n",
        " \n",
        "plot = plt.subplot(5, 2, 4)\n",
        "plot.set_title(\"chroma-yes\")\n",
        "plot.plot(chroma2)\n",
        " \n",
        "plot = plt.subplot(5, 2, 5)\n",
        "plot.set_title(\"mel-no\")\n",
        "plot.plot(mel)\n",
        " \n",
        "plot = plt.subplot(5, 2, 6)\n",
        "plot.set_title(\"mel-yes\")\n",
        "plot.plot(mel2)\n",
        " \n",
        "plot = plt.subplot(5, 2, 7)\n",
        "plot.set_title(\"contrast-no\")\n",
        "plot.plot(contrast)\n",
        " \n",
        "plot = plt.subplot(5, 2, 8)\n",
        "plot.set_title(\"contrast-yes\")\n",
        "plot.plot(contrast2)\n",
        " \n",
        "plot = plt.subplot(5, 2, 9)\n",
        "plot.set_title(\"tonnetz-no\")\n",
        "plot.plot(tonnetz)\n",
        " \n",
        "plot = plt.subplot(5, 2, 10)\n",
        "plot.set_title(\"tonnetz-yes\")\n",
        "plot.plot(tonnetz2)\n",
        " \n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}