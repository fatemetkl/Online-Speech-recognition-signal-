{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sound Recognition.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "oRMOGAqTcwie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the model (Urban Data set)\n",
        "for training this model you need to download urban data set from https://urbansounddataset.weebly.com/\n",
        "\n",
        "> \n",
        "then place folds in Sound-Data folder\n",
        ">\n",
        "you can decide which fold to be used as train data or test data\n",
        ">\n",
        "***this file is created as representation for signal processing cource project***\n"
      ]
    },
    {
      "metadata": {
        "id": "a6NmUeUSc5mz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "# feature extractoring and preprocessing data\n",
        "import librosa\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        " \n",
        "#Keras\n",
        "import keras\n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import scipy.io.wavfile as wf\n",
        "\n",
        "import pyaudio\n",
        "import wave\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile as wav\n",
        "from scipy.fftpack import fft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "734WJbnZbRn8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#functions used for feature extraction and reading file + setting labels\n",
        "\n",
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "    sr=sample_rate).T,axis=0)\n",
        "    return mfccs,stft,chroma,mel,contrast,tonnetz\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "def parse_audio_files(parent_dir,sub_dirs,file_ext=\"*.wav\"):\n",
        "    features, labels = np.empty((0,193)), np.empty(0)\n",
        "    for label, sub_dir in enumerate(sub_dirs):\n",
        "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
        "            try:\n",
        "              mfccs,stft, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
        "             \n",
        "            except Exception as e:\n",
        "              print (\"Error encountered while parsing file: \", fn)\n",
        "              continue\n",
        "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
        "            print(ext_features.shape())\n",
        "            features = np.vstack([features,ext_features]) \n",
        "            labels = np.append(labels, fn.split('/')[2].split('-')[1])\n",
        "    return np.array(features), np.array(labels, dtype = np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PC-LEETbkOl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#doing one-hot encode on labels\n",
        "\n",
        "def one_hot_encode(labels):\n",
        "    n_labels = len(labels)\n",
        "    n_unique_labels = len(np.unique(labels))\n",
        "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
        "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
        "    return one_hot_encode\n",
        "\n",
        "#defining directories for reading files\n",
        "\n",
        "parent_dir = 'Sound-Data'\n",
        "#train directory\n",
        "tr_sub_dirs = [\"fold1\",\"fold3\",\"fold5\",\"fold6\",\"fold7\"]\n",
        "#test directory\n",
        "tr_sub_dirs=[\"new\"]\n",
        "\n",
        "tr_features, tr_labels = parse_audio_files(parent_dir,tr_sub_dirs)\n",
        "ts_features, ts_labels = parse_audio_files(parent_dir,ts_sub_dirs)\n",
        "\n",
        "tr_labels = one_hot_encode(tr_labels)\n",
        "ts_labels = one_hot_encode(ts_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vQgNzfKgblvG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#defining the model \n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(tr_features.shape[1],)))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xOtib9CKbuP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#compile and fit the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model.fit(tr_features,\n",
        "          tr_labels,\n",
        "          epochs=15,\n",
        "          batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dAKTtIGbx7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#evaluating the model based on test data\n",
        "\n",
        "test_loss, test_acc = model.evaluate(ts_features,ts_labels)\n",
        "\n",
        "print(\"loss\",test_loss)\n",
        "print(\"acc\",test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IHbItb__bzKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a_opLakGb92v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# prediction part\n",
        "After now we dont need to train the model again \n",
        "\n",
        "we will just restore it and use model.predict\n"
      ]
    },
    {
      "metadata": {
        "id": "2ibDI0xhcYyt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pyaudio\n",
        "import wave\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vX6i7MjdLnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reading prediction file from user input (sound) \n",
        "#in this model it is not used for prediction due to the fact that this datas cannot be created by humans\n",
        "\n",
        "def audio_input():\n",
        "    folder = 'db/test1/'\n",
        "    for the_file in os.listdir(folder):\n",
        "        file_path = os.path.join(folder, the_file)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    # audio specifications\n",
        "    FORMAT = pyaudio.paInt16\n",
        "    CHANNELS = 2\n",
        "    RATE = 44100\n",
        "    CHUNK = 1024\n",
        "    RECORD_SECONDS = 2  # for recording 4 sec audio :\\\n",
        "    WAVE_OUTPUT_FILENAME = \"test.wav\"\n",
        "\n",
        "    audio = pyaudio.PyAudio()\n",
        "\n",
        "    # start Recording\n",
        "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
        "                        rate=RATE, input=True,\n",
        "                        frames_per_buffer=CHUNK)\n",
        "    print(\"recording...\")\n",
        "    frames = []\n",
        "\n",
        "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
        "        data = stream.read(CHUNK)\n",
        "        frames.append(data)\n",
        "    print(\"finished recording\")\n",
        "\n",
        "    # stop Recording\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    audio.terminate()\n",
        "\n",
        "    # writing the wav file into the test db/test1\n",
        "    waveFile = wave.open('db/test1/' + WAVE_OUTPUT_FILENAME, 'wb')\n",
        "    waveFile.setnchannels(CHANNELS)\n",
        "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
        "    waveFile.setframerate(RATE)\n",
        "    waveFile.writeframes(b''.join(frames))\n",
        "    waveFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mw5gW-FrdUtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#extracting features for prediction data\n",
        "def extract_feature(file_name):\n",
        "    X, sample_rate = librosa.load(file_name)\n",
        "    stft = np.abs(librosa.stft(X))\n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
        "    sr=sample_rate).T,axis=0)\n",
        "    return mfccs,chroma,mel,contrast,tonnetz\n",
        "\n",
        "def parse_audio_files_pred(parent_dir,sub_dirs,file_ext=\"*.wav\"):\n",
        "    features = np.empty((0,193))\n",
        "    for label, sub_dir in enumerate(sub_dirs):\n",
        "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
        "            mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
        "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
        "            features = np.vstack([features,ext_features])\n",
        "    return np.array(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8nqpxcgUdaIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parent_dir = 'Sound-Data'\n",
        "pred_sub_dirs = [\"test\"]\n",
        "pred_features=parse_audio_files_pred(parent_dir,pred_sub_dirs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_wHmu8TdhXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpZF_bFkdoJV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#prediction part\n",
        "pred_features = parse_audio_files_pred(parent_dir, pred_sub_dirs)\n",
        "predictions = loaded_model.predict(pred_features)\n",
        "result = np.argmax(predictions[0])\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CWpoo0MQdoip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}